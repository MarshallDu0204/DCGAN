{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "53bhC-bWye8m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "c45f16e4-8979-45a3-c40b-9f6bb984c531"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JmJ-yP9zn2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "275a802d-4845-4d9d-9ec0-43dc9b02298f"
      },
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import UpSampling2D, Conv2D, Activation, BatchNormalization, Reshape, Dense, Input, LeakyReLU, Dropout, Flatten, ZeroPadding2D\n",
        "from keras.optimizers import Adam,SGD"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIPkYnOkLU2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator():\n",
        "    noise_shape = (100,)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64 * (192 // (2 ** 5)) * (256 // (2 ** 5)), activation=\"relu\", input_shape=noise_shape))\n",
        "    model.add(Reshape(((192 // (2 ** 5)), (256 // (2 ** 5)), 64)))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(1024, (3, 3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(512, (3, 3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(256, (3, 3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, (3, 3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Conv2D(3, (3, 3), padding = 'same'))\n",
        "    model.add(Activation('tanh'))\n",
        "\n",
        "    noise = Input(shape = noise_shape)\n",
        "    img = model(noise)\n",
        "\n",
        "    return model\n",
        "\n",
        "def build_discriminator():\n",
        "        \n",
        "    img_shape = (192, 256, 3)\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), strides = 2, input_shape=img_shape, padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), strides = 2, padding = 'same'))\n",
        "    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), strides = 2, padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), strides = 1, padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "        \n",
        "    model.add(Conv2D(512, (3, 3), strides = 1, padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "def combine_model(g,d):\n",
        "    model = Sequential()\n",
        "    model.add(g)\n",
        "    d.trainable = False\n",
        "    model.add(d)\n",
        "    return model\n",
        "\n",
        "def get_data(imgPath):\n",
        "    basePath = '/content/drive/My Drive/Colab Notebooks/DCGAN-data/'\n",
        "    X = []\n",
        "    for path in tqdm(imgPath):\n",
        "        img = Image.open(basePath + path)\n",
        "        img = np.asarray(img)\n",
        "        X.append(img)\n",
        "    return np.asarray(X)\n",
        "\n",
        "def gene_imgs(count,g):\n",
        "    noise = np.random.normal(0, 1, (count, 100))\n",
        "    return g.predict(noise)\n",
        "    \n",
        "def save_imgs(epoch,g):\n",
        "    r, c = 5, 5\n",
        "\n",
        "    imgs = gene_imgs(r*c,g)\n",
        "    imgs = 127.5 * imgs + 127.5\n",
        "\n",
        "    nindex, height, width, intensity = imgs.shape\n",
        "    nrows = nindex // c\n",
        "    assert nindex == nrows * c\n",
        "        \n",
        "    gallery = (imgs.reshape(nrows, c, height, width, intensity)\n",
        "                  .swapaxes(1, 2)\n",
        "                  .reshape(height * nrows, width * c, intensity))\n",
        "    path = '/content/drive/My Drive/Colab Notebooks/gantest' + '/gallery'\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    cv2.imwrite(path + f\"/{epoch}.jpg\", gallery)\n",
        "\n",
        "def trainModel():\n",
        "    pathList = os.listdir('/content/drive/My Drive/Colab Notebooks/DCGAN-data/')\n",
        "    X_train = get_data(pathList)\n",
        "\n",
        "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "    BATCH_SIZE = 16\n",
        "    \n",
        "    d = build_discriminator()\n",
        "    g = build_generator()\n",
        "    d_on_g = combine_model(g, d)\n",
        "\n",
        "    d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "    g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
        "    d_on_g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
        "    d.trainable = True\n",
        "    d.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
        "    losses = np.zeros((47, 2))\n",
        "    for epoch in tqdm(range(10000)):\n",
        "        print(\"Epoch is\", epoch)\n",
        "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
        "            noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
        "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
        "            generated_images = g.predict(noise, verbose=0)\n",
        "            X = np.concatenate((image_batch, generated_images))\n",
        "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
        "            d_loss = d.train_on_batch(X, y)\n",
        "            losses[index-1, 0] = d_loss\n",
        "            noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
        "            d.trainable = False\n",
        "            g_loss = d_on_g.train_on_batch(noise, [1] * BATCH_SIZE)\n",
        "            d.trainable = True\n",
        "            losses[index-1, 1] = g_loss\n",
        "        if epoch % 20 == 0:\n",
        "            print(\"Epoch is\", epoch)\n",
        "            print('d_loss',np.mean(losses[:, 0]),'g_loss',np.mean(losses[:, 1]))\n",
        "            save_imgs(epoch,g)\n",
        "            g.save_weights('/content/drive/My Drive/Colab Notebooks/model/generator.h5', True)\n",
        "            d.save_weights('/content/drive/My Drive/Colab Notebooks/model/discriminator.h5', True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXJr7E9TYvZ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef913e2e-a580-4b6e-bd22-eaeb32f759aa"
      },
      "source": [
        "trainModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 143/756 [00:47<03:27,  2.95it/s]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}