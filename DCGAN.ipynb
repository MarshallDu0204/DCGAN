{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "53bhC-bWye8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JmJ-yP9zn2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import UpSampling2D, Conv2D, Activation, BatchNormalization, Reshape, Dense, Input, LeakyReLU, Dropout, Flatten, ZeroPadding2D\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLHcM1Yxyiow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "class DCGAN:\n",
        "    def __init__(self):\n",
        "        self.discriminator_path = '/content/drive/My Drive/Colab Notebooks/model/discriminator.h5'\n",
        "        self.generator_path = '/content/drive/My Drive/Colab Notebooks/model/generator.h5'\n",
        "        self.output_directory = '/content/drive/My Drive/Colab Notebooks/gantest'\n",
        "    \n",
        "    def build_generator(self):\n",
        "        noise_shape = (100,)\n",
        "        model = Sequential()\n",
        "        model.add(Dense(64 * (192 // (2 ** 5)) * (256 // (2 ** 5)), activation=\"relu\", input_shape=noise_shape))\n",
        "        model.add(Reshape(((192 // (2 ** 5)), (256 // (2 ** 5)), 64)))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(1024, (3, 3), padding = 'same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(512, (3, 3), padding = 'same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(256, (3, 3), padding = 'same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(128, (3, 3), padding = 'same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(Conv2D(32, (3, 3), padding = 'same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(Conv2D(3, (3, 3), padding = 'same'))\n",
        "        model.add(Activation('relu'))\n",
        "\n",
        "        noise = Input(shape = noise_shape)\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "    \n",
        "    def build_discriminator(self):\n",
        "        \n",
        "        img_shape = (192, 256, 3)\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(32, (3, 3), strides = 2, input_shape=img_shape, padding = 'same'))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), strides = 2, padding = 'same'))\n",
        "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(Conv2D(128, (3, 3), strides = 2, padding = 'same'))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), strides = 1, padding = 'same'))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        model.add(Conv2D(512, (3, 3), strides = 1, padding = 'same'))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "        img = Input(shape = img_shape)\n",
        "        result = model(img)\n",
        "\n",
        "        return Model(img, result)\n",
        "    \n",
        "    def build_model(self):\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "        if os.path.exists(self.discriminator_path) and os.path.exists(self.generator_path):\n",
        "            self.discriminator = load_model(self.discriminator_path)\n",
        "            self.generator = load_model(self.generator_path)\n",
        "            print(\"Loaded models...\")\n",
        "        else:\n",
        "            self.discriminator = self.build_discriminator()\n",
        "            self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "            self.generator = self.build_generator()\n",
        "            self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "            random_noise = Input(shape = (100,))\n",
        "            img = self.generator(random_noise)\n",
        "\n",
        "            self.discriminator.trainable = False\n",
        "\n",
        "            result = self.discriminator(img)\n",
        "\n",
        "            self.combined = Model(random_noise, result)\n",
        "            self.combined.compile(loss = 'binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    def get_data(self,imgPath):\n",
        "        basePath = '/content/drive/My Drive/Colab Notebooks/DCGAN-data/'\n",
        "        X = []\n",
        "        for path in tqdm(imgPath):\n",
        "            img = Image.open(basePath + path)\n",
        "            img = np.asarray(img)\n",
        "            X.append(img)\n",
        "        return np.asarray(X)\n",
        "    \n",
        "    def trainModel(self):\n",
        "        self.build_model()\n",
        "        pathList = os.listdir('/content/drive/My Drive/Colab Notebooks/DCGAN-data/')\n",
        "        X_train = self.get_data(pathList)\n",
        "\n",
        "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "        batch_size = 32\n",
        "        half_batch = batch_size // 2\n",
        "\n",
        "        epochs = 500\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "            index = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "            imgs = X_train[idx]\n",
        "\n",
        "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            print(f\"{epoch} [D loss: {d_loss[0]} | D Accuracy: {d_loss[1]}] [G loss: {g_loss}]\")\n",
        "\n",
        "            if epoch % (50) == 0:\n",
        "                self.save_imgs(epoch)\n",
        "                self.discriminator.save(self.discriminator_path)\n",
        "                self.generator.save(self.generator_path)\n",
        "    def gene_imgs(self, count):\n",
        "        noise = np.random.normal(0, 1, (count, 100))\n",
        "        return self.generator.predict(noise)\n",
        "    \n",
        "    def save_imgs(self,epoch):\n",
        "        r, c = 5, 5\n",
        "\n",
        "        imgs = self.gene_imgs(r*c)\n",
        "        imgs = 0.5 * imgs + 0.5\n",
        "\n",
        "        nindex, height, width, intensity = imgs.shape\n",
        "        nrows = nindex // c\n",
        "        assert nindex == nrows * c\n",
        "        \n",
        "        gallery = (imgs.reshape(nrows, c, height, width, intensity)\n",
        "                  .swapaxes(1, 2)\n",
        "                  .reshape(height * nrows, width * c, intensity))\n",
        "        path = self.output_directory + '/gallery'\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "        imsave(path + f\"/{epoch}.jpg\", gallery)\n",
        "\n",
        "    def predict_img(self, count, threshold):\n",
        "        self.build_model()\n",
        "\n",
        "        imgs = []\n",
        "        for i in range(count):\n",
        "            score = [0]\n",
        "            while not(threshold[0] < score[0] < threshold[1]):\n",
        "                img = self.gene_imgs(1)\n",
        "                score = self.discriminator.predict(img)\n",
        "            print(\"Image found: \", score[0])\n",
        "            imgs.append(img)\n",
        "\n",
        "        imgs = np.asarray(imgs).squeeze()\n",
        "        imgs = 0.5 * imgs + 0.5\n",
        "        for i, img_array in enumerate(imgs):\n",
        "            path = self.output_directory + '/predictimg'\n",
        "            if not os.path.exists(path):\n",
        "                os.makedirs(path)\n",
        "            imsave(path + f\"/{i}.png\", img_array)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFNGdYo0y1yN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dcgan = DCGAN()\n",
        "dcgan.trainModel()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}